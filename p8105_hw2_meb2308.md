P8105 Homework 2 Solutions
================
Meghan Bellerose,
September 24, 2020

This homework uses r version 4.0.2 and r studio version 1.3.1073.

For this homework, I need the tidyverse and readxl libraries.

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

### Read and clean Mr. Trash Wheel data

First, I will read the Mr. Trash Wheel Excel data sheet, create snake
format variable names, and omit non-data entries, including rows and
columns with notes and figures, as well as entries that are unrelated to
the dumpster data.

I’ll also round the number of sports balls to the nearest integer and
convert the results to an integer variable.

``` r
trashwheel_df =
  read_xlsx("./data/trash_wheel.xlsx",
  sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N")) %>%
  janitor:: clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  ) 
```

### Read and clean precipitation data

Next, I’ll read and clean the precipitation data for 2017 and 2018,
omitting rows without data and adding a variable for year.

``` r
precip_2018 = 
  read_excel("./data/trash_wheel.xlsx",
      sheet = "2018 Precipitation",
      skip = 1
  ) %>%
  janitor:: clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel("./data/trash_wheel.xlsx",
      sheet = "2017 Precipitation",
      skip = 1
  ) %>%
  janitor:: clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now I will combine the precipitation datasets and convert month to a
character variable using month.name.

``` r
precip_df = 
  bind_rows(precip_2017, precip_2018) %>%
  mutate(month = month.name[month])
```

The square bracket vector is not ideal, so we can create a month data
frame instead.

``` r
options(tibble.print_min = 3)

month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2017, precip_2018)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##    year month total month_name
    ##   <dbl> <dbl> <dbl> <chr>     
    ## 1  2017     1  2.34 January   
    ## 2  2017     2  1.46 February  
    ## 3  2017     3  3.57 March     
    ## # … with 21 more rows

This dataset contains information from the Mr. Trashwheel collector in
Baltimore, MD. As trash enters the inner harbor, the trashwheel collects
the trash and stores it in a dumpster. The dataset contains information
on year, month, weight of the trash collected, and the number of some
specific types of trash, such as plastic bottles or sports balls. For
instance, in 2017, the median number of sports balls inside a dumpster
after collection was 8 balls. There are 344 rows in our final dataset.

Additional data sheets include monthly precipitation data. In 2017, the
mean precipitation was 2.7 inches, and in 2018 it was 5.9 inches.

This code can be used with the 2020 data, because the sheet names are
consistent\!

# Problem 2

### Read and clean the NYC Transit dataset

I will read and clean the NYC transit dataset, keeping important
variables. I then convert the entry variable from a character to a
logical variable.

``` r
options(tibble.print_min = 3)

subway_df =
  read_csv("./data/subway.csv", 
    col_types = "cccnnccccccccccccccccclclcccnncc") %>%
  janitor:: clean_names() %>%
  mutate(
    entry = replace(entry, entry == "YES", "TRUE"),
    entry = replace(entry, entry == "NO", "FALSE")) %>% 
  mutate(entry = as.logical(entry)) %>% 
  select(
      line, station_name, station_location, route1:route11, vending, entry, entrance_type, ada) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_order",
    names_prefix = "route",
    values_to = "route") %>%
  drop_na(route)

subway_df
```

    ## # A tibble: 4,270 x 9
    ##   line  station_name station_location vending entry entrance_type ada  
    ##   <chr> <chr>        <chr>            <chr>   <lgl> <chr>         <lgl>
    ## 1 4 Av… 25th St      (40.660397, -73… YES     TRUE  Stair         FALSE
    ## 2 4 Av… 25th St      (40.660397, -73… YES     TRUE  Stair         FALSE
    ## 3 4 Av… 36th St      (40.655144, -74… YES     TRUE  Stair         FALSE
    ## # … with 4,267 more rows, and 2 more variables: route_order <chr>, route <chr>

This dataset contains information about the NYC transit systems’ subway
stations. I cleaned the dataset so that variable names are in snake
format and only retained information on the station names and locations,
the routes that are served by each station during weekday service,
whether the location allows entry, the entrance type, whether vending
machines are available, and whether it is ADA accessible. I tidied the
data so that routes 1 through 11 were listed in a single column rather
than 11 columns and rows with NA are removed. I then converted entry
from a character to a logical vector. There are 4270 rows and 9 columns
in the final dataset. I consider the data to be tidy.

### NYC Transit system details

Next, I will find the number of distinct stations, the number of ADA
compliant stations, and the proportion of stations without vending
machines that allow entrance.

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   356

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    73

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   447

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   139

    ##          n
    ## 1 0.310962

There are 356 distinct stations, and 73 are ADA compliant. Among the 447
stations without vending machines, 139 allow entry, giving a proportion
of 31.1%.

I already made the route number and name distinct variables during my
data tidying process. I determine how many stations serve the A train,
and among those, how many are ADA compliant.

``` r
filter (subway_df, route == "A") %>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   273

``` r
filter (subway_df, route == "A", ada == "TRUE") %>% 
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   107

There are 273 distinct stations that serve the A train. Of these, 107
are ADA compliant.

# Problem 3

### Read and clean FiveThirtyEight data

First I read and clean the data in the pols-month csv file. I break the
date variable into day, month, and year then remove day. I will then
create a variable for president and remove the base variables used to
create it.

``` r
options(tibble.print_min = 3)

pols_df =
  read_csv("./data/pols-month.csv") %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate(
    prez_dem = replace(prez_dem, prez_dem == 1, "dem"),
    prez_dem = replace(prez_dem, prez_dem == 0, "gop"),
    president = prez_dem
  ) %>%
  mutate(
    year = as.integer(year),
    month = as.integer(month) 
  ) %>% 
  select(year, month, president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

I’ll repeat this process for the snp csv file and arrange the data file
so that year and month are first.

``` r
snp_df =
  read_csv("./data/snp.csv") %>% 
  separate(date, c("month", "day", "year")) %>% 
  mutate(
    year = as.integer(year),
    month = as.integer(month) 
  ) %>% 
  select (year, month, close)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Now I tidy the unemployment data to prepare it for merging. I also
change it from wide to long format.

``` r
unemployment_df =
  read_csv("./data/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month_name",
    values_to = "percent_unemployed"
  ) %>% 
  rename(
    year = Year
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.abb
  )

unemployment_month_data = 
  left_join(unemployment_df, month_df, by = "month_name") %>% 
  select(year, month, percent_unemployed)
```

Now I join the three datasets.

``` r
pols_snp_unemp = 
  left_join(pols_df, snp_df, unemployment_month_data, by = c("year", "month"))
```

This dataset was generated using data from three datasets created by the
FiveThirtyEight project. The pols dataset contains information on the
number of republican (GOP) and democratic political leaders at different
dates and whether the president was a Democrat or Republican. The
unemployment dataset provides the percentage of people who were
unemployed in the U.S. during each month. The snp dataset contains the
closing values of the S\&P stock index on various dates. The final
dataset has 822 rows and 10 columns, and has a range of (1947, 2015)
years. The key variable names are: year, month, president, gov\_gop,
sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem, close.
